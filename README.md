# ğŸ” Depth Estimation Using MiDaS (PyTorch)
This project uses **monocular depth estimation** using the **MiDaS deep learning model**, a state-of-the-art deep learning model that predicts scene depth from a **2D RGB image**. It processes a batch of images, generates corresponding depth maps, and optionally saves the results. This implementation is designed for use in a **Jupyter notebook**.


## ğŸ“¸ Example Outputs
| Original Image vs Depth Map            |
| -------------------------------------- |
| ![Original vs Depth](city_example.png) |


## ğŸ“Œ Features
- ğŸ” High-quality monocular depth estimation (MiDaS)
- ğŸ“· Batch processing of images
- ğŸ¨ Visualization using Matplotlib with customizable colormaps
- ğŸ’¾ Output storage as .png and optional .npz format
- âš™ï¸ Configurable parameters for device, model, size, and layout


## ğŸ“‚ Project Structure
- â”œâ”€â”€ dataset/                      # Input images
- â”œâ”€â”€ outputs/                      # Depth map results
- â”œâ”€â”€ city_example.png              # Image example Original vs Depth
- â”œâ”€â”€ Depth_Estimation_Midas.ipynb  # Jupyter notebook
- â””â”€â”€ README.md                     # Project documentation


## ğŸ“‚ Dataset
The project expects a folder named `/dataset` containing 30 input RGB images.


## ğŸ”§ Requirements
This project is designed to run on **Jupyter notebook**, but locally you would need:

- `torch`, `torchvision`
- `opencv-python`
- `matplotlib`
- `tqdm`
- `numpy`

You can install them using:

```bash
pip install torch torchvision tqdm matplotlib opencv-python
```


## ğŸ§  Model: MiDaS (DPT_Large)
We use the `MiDaS v3` model `DPT_Large` (based on Vision Transformers) for best accuracy, loaded via PyTorch Hub:

- Paper: [MiDaS: Robust Monocular Depth Estimation](https://arxiv.org/abs/1907.01341)
- GitHub: [intel-isl/MiDaS](https://github.com/intel-isl/MiDaS)
- Architecture: DPT (Dense Prediction Transformer)

You can easily switch to lighter variants like `DPT_Hybrid` or `MiDaS_small` for faster inference.


## ğŸ“¦ Output Formats
- NG: Depth maps saved as grayscale images
- NPZ: Combined RGB + depth + metadata for postprocessing


## ğŸ“˜ Language
- Python
